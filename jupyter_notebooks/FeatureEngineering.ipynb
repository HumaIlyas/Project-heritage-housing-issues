{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "* Drop features that are correlated with other features\n",
    "* Transform continuous variables\n",
    "\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* outputs/datasets/collection/HousePricesRecords.csv\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Generate a pipeline including data cleaning and feature engineering\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "* Six more features could be dropped leaving 15 features out of the original 23 (two were dropped in the data cleaning step).\n",
    "* The numerical transformations significantly improved the distribution of two variables including the target (the sale price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/Project-heritage-housing-issues/jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory.\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chdir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/Project-heritage-housing-issues'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = (pd.read_csv(\"outputs/datasets/collection/HousePricesRecords.csv\"))\n",
    "df.head(3)"
   ]
  },
  {
   "source": [
    "## SmartCorrelatedSelection Variables\n",
    "\n",
    "* Add SmartCorrelatedSelection to the pipeline to drop features that are correlated with other features and therefore do not add any new information"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Pipeline steps needed\n",
    "### Drop features\n",
    "from feature_engine.selection import DropFeatures\n",
    "\n",
    "### Median Imputer\n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "\n",
    "### Correlation selection\n",
    "from feature_engine.selection import SmartCorrelatedSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Encoder from DataCleaning notebook\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class MyCustomEncoder(BaseEstimator, TransformerMixin):\n",
    "\n",
    "  def __init__(self, variables, dic):\n",
    "    if not isinstance(variables, list): \n",
    "      self.variables = [variables]\n",
    "    else: self.variables = variables\n",
    "    self.dic = dic\n",
    "\n",
    "  def fit(self, X, y=None):    \n",
    "    return self\n",
    "\n",
    "  def transform(self, X):\n",
    "    for col in self.variables:\n",
    "      if X[col].dtype == 'object':\n",
    "        X[col] = X[col].replace(dic[col])\n",
    "      else:\n",
    "        print(f\"Warning: {col} data type should be object to use MyCustomEncoder()\")\n",
    "      \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dic and vars_with_missing_data is needed for data cleaning - See the DataCleaning notebook\n",
    "df2 = df.copy().drop('SalePrice', axis=1)\n",
    "dic = {'BsmtExposure': {'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, 'None': 0}, 'BsmtFinType1': {'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, 'None': 0}, 'GarageFinish': {'Fin': 3, 'RFn': 2, 'Unf': 1, 'None': 0}, 'KitchenQual': {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'Po': 0}}\n",
    "vars_with_missing_data = ['2ndFlrSF', 'BedroomAbvGr', 'BsmtFinType1', 'GarageFinish', 'GarageYrBlt', 'LotFrontage', 'MasVnrArea']\n",
    "\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "\n",
    "pipeline = Pipeline([\n",
    "      ('drop_features', DropFeatures(features_to_drop = ['EnclosedPorch', 'WoodDeckSF'])),\n",
    "      ('custom_encoder', MyCustomEncoder(variables=['BsmtExposure', 'BsmtFinType1', 'GarageFinish', 'KitchenQual'], dic=dic)),\n",
    "      ('median_imputer',  MeanMedianImputer(imputation_method='median', variables=vars_with_missing_data)),\n",
    "      ('corr_sel', SmartCorrelatedSelection(method=\"spearman\", threshold=0.6, selection_method=\"variance\"))\n",
    "])\n",
    "\n",
    "df_transformed = pipeline.fit_transform(df2) \n",
    "df_transformed.info()"
   ]
  },
  {
   "source": [
    "* Show the groups with correlated features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline['corr_sel'].correlated_feature_sets_"
   ]
  },
  {
   "source": [
    "* Show the removed features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline['corr_sel'].features_to_drop_"
   ]
  },
  {
   "source": [
    "##  Transform numerical variables\n",
    "Custom code from Code Institute Scikit-learn module"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine import transformation as vt\n",
    "from feature_engine.outliers import Winsorizer\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "sns.set(style=\"whitegrid\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "def FeatureEngineeringAnalysis(df,analysis_type=None):\n",
    "\n",
    "\n",
    "  \"\"\"\n",
    "  - used for quick feature engineering on numerical and categorical variables\n",
    "  to decide which transformation can better transform the distribution shape \n",
    "  - Once transformed, use a reporting tool, like pandas-profiling, to evaluate distributions\n",
    "\n",
    "  \"\"\"\n",
    "  check_missing_values(df)\n",
    "  allowed_types= ['numerical', 'ordinal_encoder',  'outlier_winsorizer']\n",
    "  check_user_entry_on_analysis_type(analysis_type, allowed_types)\n",
    "  list_column_transformers = define_list_column_transformers(analysis_type)\n",
    "  \n",
    "  \n",
    "  # Loop in each variable and engineer the data according to the analysis type\n",
    "  df_feat_eng = pd.DataFrame([])\n",
    "  for column in df.columns:\n",
    "    # create additional columns (column_method) to apply the methods\n",
    "    df_feat_eng = pd.concat([df_feat_eng, df[column]], axis=1)\n",
    "    for method in list_column_transformers:\n",
    "      df_feat_eng[f\"{column}_{method}\"] = df[column]\n",
    "      \n",
    "    # Apply transformers in respectives column_transformers\n",
    "    df_feat_eng,list_applied_transformers = apply_transformers(analysis_type, df_feat_eng, column)\n",
    "\n",
    "    # For each variable, assess how the transformations perform\n",
    "    transformer_evaluation(column, list_applied_transformers, analysis_type, df_feat_eng)\n",
    "\n",
    "  return df_feat_eng\n",
    "\n",
    "\n",
    "def check_user_entry_on_analysis_type(analysis_type, allowed_types):\n",
    "  ### Check analyis type\n",
    "  if analysis_type == None:\n",
    "    raise SystemExit(f\"You should pass analysis_type parameter as one of the following options: {allowed_types}\")\n",
    "  if analysis_type not in allowed_types:\n",
    "      raise SystemExit(f\"analysis_type argument should be one of these options: {allowed_types}\")\n",
    "\n",
    "def check_missing_values(df):\n",
    "  if df.isna().sum().sum() != 0:\n",
    "    raise SystemExit(\n",
    "        f\"There is missing value in your dataset. Please handle that before getting into feature engineering.\")\n",
    "\n",
    "\n",
    "\n",
    "def define_list_column_transformers(analysis_type):\n",
    "  ### Set suffix colummns acording to analysis_type\n",
    "  if analysis_type=='numerical':\n",
    "    list_column_transformers = [\"log_e\",\"log_10\",\"reciprocal\", \"power\",\"box_cox\",\"yeo_johnson\"]\n",
    "  \n",
    "  elif analysis_type=='ordinal_encoder':\n",
    "    list_column_transformers = [\"ordinal_encoder\"]\n",
    "\n",
    "  elif analysis_type=='outlier_winsorizer':\n",
    "    list_column_transformers = ['iqr']\n",
    "\n",
    "  return list_column_transformers\n",
    "\n",
    "\n",
    "\n",
    "def apply_transformers(analysis_type, df_feat_eng, column):\n",
    "\n",
    "\n",
    "  for col in df_feat_eng.select_dtypes(include='category').columns:\n",
    "    df_feat_eng[col] = df_feat_eng[col].astype('object')\n",
    "\n",
    "\n",
    "  if analysis_type=='numerical':\n",
    "    df_feat_eng,list_applied_transformers = FeatEngineering_Numerical(df_feat_eng,column)\n",
    "  \n",
    "  elif analysis_type=='outlier_winsorizer':\n",
    "    df_feat_eng,list_applied_transformers = FeatEngineering_OutlierWinsorizer(df_feat_eng,column)\n",
    "\n",
    "  elif analysis_type=='ordinal_encoder':\n",
    "    df_feat_eng,list_applied_transformers = FeatEngineering_CategoricalEncoder(df_feat_eng,column)\n",
    "\n",
    "  return df_feat_eng,list_applied_transformers\n",
    "\n",
    "\n",
    "\n",
    "def transformer_evaluation(column, list_applied_transformers, analysis_type, df_feat_eng):\n",
    "  # For each variable, assess how the transformations perform\n",
    "  print(f\"* Variable Analyzed: {column}\")\n",
    "  print(f\"* Applied transformation: {list_applied_transformers} \\n\")\n",
    "  for col in [column] + list_applied_transformers:\n",
    "    \n",
    "    if analysis_type!='ordinal_encoder':\n",
    "      DiagnosticPlots_Numerical(df_feat_eng, col)\n",
    "    \n",
    "    else:\n",
    "      if col == column: \n",
    "        DiagnosticPlots_Categories(df_feat_eng, col)\n",
    "      else:\n",
    "        DiagnosticPlots_Numerical(df_feat_eng, col)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "def DiagnosticPlots_Categories(df_feat_eng, col):\n",
    "  plt.figure(figsize=(4, 3))\n",
    "  sns.countplot(data=df_feat_eng, x=col,palette=['#432371'],order = df_feat_eng[col].value_counts().index)\n",
    "  plt.xticks(rotation=90) \n",
    "  plt.suptitle(f\"{col}\", fontsize=30,y=1.05)        \n",
    "  plt.show()\n",
    "  print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "def DiagnosticPlots_Numerical(df, variable):\n",
    "  fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "  sns.histplot(data=df, x=variable, kde=True,element=\"step\",ax=axes[0]) \n",
    "  stats.probplot(df[variable], dist=\"norm\", plot=axes[1])\n",
    "  sns.boxplot(x=df[variable],ax=axes[2])\n",
    "  \n",
    "  axes[0].set_title('Histogram')\n",
    "  axes[1].set_title('QQ Plot')\n",
    "  axes[2].set_title('Boxplot')\n",
    "  fig.suptitle(f\"{variable}\", fontsize=30,y=1.05)\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def FeatEngineering_CategoricalEncoder(df_feat_eng,column):\n",
    "  list_methods_worked = []\n",
    "  try:  \n",
    "    encoder= OrdinalEncoder(encoding_method='arbitrary', variables = [f\"{column}_ordinal_encoder\"])\n",
    "    df_feat_eng = encoder.fit_transform(df_feat_eng)\n",
    "    list_methods_worked.append(f\"{column}_ordinal_encoder\")\n",
    "  \n",
    "  except: \n",
    "    df_feat_eng.drop([f\"{column}_ordinal_encoder\"],axis=1,inplace=True)\n",
    "    \n",
    "  return df_feat_eng,list_methods_worked\n",
    "\n",
    "\n",
    "def FeatEngineering_OutlierWinsorizer(df_feat_eng,column):\n",
    "  list_methods_worked = []\n",
    "\n",
    "  ### Winsorizer iqr\n",
    "  try: \n",
    "    disc=Winsorizer(\n",
    "        capping_method='iqr', tail='both', fold=1.5, variables = [f\"{column}_iqr\"])\n",
    "    df_feat_eng = disc.fit_transform(df_feat_eng)\n",
    "    list_methods_worked.append(f\"{column}_iqr\")\n",
    "  except: \n",
    "    df_feat_eng.drop([f\"{column}_iqr\"],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "  return df_feat_eng,list_methods_worked\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def FeatEngineering_Numerical(df_feat_eng,column):\n",
    "\n",
    "  list_methods_worked = []\n",
    "\n",
    "  ### LogTransformer base e\n",
    "  try: \n",
    "    lt = vt.LogTransformer(variables = [f\"{column}_log_e\"])\n",
    "    df_feat_eng = lt.fit_transform(df_feat_eng)\n",
    "    list_methods_worked.append(f\"{column}_log_e\")\n",
    "  except: \n",
    "    df_feat_eng.drop([f\"{column}_log_e\"],axis=1,inplace=True)\n",
    "\n",
    "    ### LogTransformer base 10\n",
    "  try: \n",
    "    lt = vt.LogTransformer(variables = [f\"{column}_log_10\"],base='10')\n",
    "    df_feat_eng = lt.fit_transform(df_feat_eng)\n",
    "    list_methods_worked.append(f\"{column}_log_10\")\n",
    "  except: \n",
    "    df_feat_eng.drop([f\"{column}_log_10\"],axis=1,inplace=True)\n",
    "\n",
    "  ### ReciprocalTransformer\n",
    "  try:\n",
    "    rt = vt.ReciprocalTransformer(variables = [f\"{column}_reciprocal\"])\n",
    "    df_feat_eng =  rt.fit_transform(df_feat_eng)\n",
    "    list_methods_worked.append(f\"{column}_reciprocal\")\n",
    "  except:\n",
    "    df_feat_eng.drop([f\"{column}_reciprocal\"],axis=1,inplace=True)\n",
    "\n",
    "  ### PowerTransformer\n",
    "  try:\n",
    "    pt = vt.PowerTransformer(variables = [f\"{column}_power\"])\n",
    "    df_feat_eng = pt.fit_transform(df_feat_eng)\n",
    "    list_methods_worked.append(f\"{column}_power\")\n",
    "  except:\n",
    "    df_feat_eng.drop([f\"{column}_power\"],axis=1,inplace=True)\n",
    "\n",
    "  ### BoxCoxTransformer\n",
    "  try:\n",
    "    bct = vt.BoxCoxTransformer(variables = [f\"{column}_box_cox\"])\n",
    "    df_feat_eng = bct.fit_transform(df_feat_eng)\n",
    "    list_methods_worked.append(f\"{column}_box_cox\")\n",
    "  except:\n",
    "    df_feat_eng.drop([f\"{column}_box_cox\"],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "  ### YeoJohnsonTransformer\n",
    "  try:\n",
    "    yjt = vt.YeoJohnsonTransformer(variables = [f\"{column}_yeo_johnson\"])\n",
    "    df_feat_eng = yjt.fit_transform(df_feat_eng)\n",
    "    list_methods_worked.append(f\"{column}_yeo_johnson\")\n",
    "  except:\n",
    "        df_feat_eng.drop([f\"{column}_yeo_johnson\"],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "  return df_feat_eng,list_methods_worked"
   ]
  },
  {
   "source": [
    "* The variables remaining after the previous pipeline are:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_after_corr_sel = df_transformed.columns.to_list()\n",
    "variables_after_corr_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "* The tranformations can only be applied to continuous variables, leaving nine out of 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_engineering = ['BsmtFinSF1', 'BsmtUnfSF', 'GarageArea', 'GrLivArea', 'LotArea', 'LotFrontage', 'MasVnrArea', 'OpenPorchSF', 'TotalBsmtSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineering = df_transformed[variables_engineering].copy()\n",
    "df_engineering.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineering = FeatureEngineeringAnalysis(df=df_engineering, analysis_type='numerical')"
   ]
  },
  {
   "source": [
    "* Check log_e tranformation on 'GrLivArea'"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineering[['GrLivArea', 'GrLivArea_log_e']].head(3)"
   ]
  },
  {
   "source": [
    "* The log_e transformation improves the QQ-plot of 'GrLivArea' subtantially. The power transformation improves 'BmstUnfSF' and 'OpenPorchSF' somewhat. The other variables are not improved by the transformations."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Transform the target variable, i. e. the sale price"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df['SalePrice'].to_frame()\n",
    "df_target.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = FeatureEngineeringAnalysis(df=df_target, analysis_type='numerical')"
   ]
  },
  {
   "source": [
    "* The log_e, log, BoxCox and YeoJohnson improve the sale price distribution as can be seen from the QQ-plot."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}