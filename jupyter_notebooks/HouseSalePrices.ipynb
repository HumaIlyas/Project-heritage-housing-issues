{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Sale Prices Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "* Answer business requirement 1:\n",
    "    * The client is interested in discovering how the house attributes correlate with the sale price. Therefore, the client expects data visualizations of the correlated variables against the sale price to show that\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* outputs/datasets/collection/HousePricesRecords.csv\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Calculate the correlation coefficients between the house attributes and the sale price and visualize in a heat map. Create scatterplots of each correlated attribute against the sell price.\n",
    "\n",
    "* Save correlation coefficients to:\n",
    "outputs/house_prices_study/v1/corr_df_rev.csv\n",
    "\n",
    "* Save dictionary used in encoding object variables to:\n",
    "outputs/house_prices_study/v1/dic.pkl\n",
    "\n",
    "## Conclusions\n",
    "* Seven variables out of 23 are strongly correlated with sale price\n",
    "* The sale price distribution is skewed to the right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: '/workspaces/Project-heritage-housing-issues/requirements.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r /workspaces/Project-heritage-housing-issues/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/Project-heritage-housing-issues/jupyter_notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory.\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chdir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/Project-heritage-housing-issues'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>...</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>854.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>706</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>548</td>\n",
       "      <td>RFn</td>\n",
       "      <td>...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>978</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>460</td>\n",
       "      <td>RFn</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920</td>\n",
       "      <td>866.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Mn</td>\n",
       "      <td>486</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>608</td>\n",
       "      <td>RFn</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>216</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>642</td>\n",
       "      <td>Unf</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Av</td>\n",
       "      <td>655</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>836</td>\n",
       "      <td>RFn</td>\n",
       "      <td>...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>84</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType1  \\\n",
       "0       856     854.0           3.0           No         706          GLQ   \n",
       "1      1262       0.0           3.0           Gd         978          ALQ   \n",
       "2       920     866.0           3.0           Mn         486          GLQ   \n",
       "3       961       NaN           NaN           No         216          ALQ   \n",
       "4      1145       NaN           4.0           Av         655          GLQ   \n",
       "\n",
       "   BsmtUnfSF  EnclosedPorch  GarageArea GarageFinish  ...  LotFrontage  \\\n",
       "0        150            0.0         548          RFn  ...         65.0   \n",
       "1        284            NaN         460          RFn  ...         80.0   \n",
       "2        434            0.0         608          RFn  ...         68.0   \n",
       "3        540            NaN         642          Unf  ...         60.0   \n",
       "4        490            0.0         836          RFn  ...         84.0   \n",
       "\n",
       "   MasVnrArea OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  WoodDeckSF  \\\n",
       "0       196.0          61            5            7          856         0.0   \n",
       "1         0.0           0            8            6         1262         NaN   \n",
       "2       162.0          42            5            7          920         NaN   \n",
       "3         0.0          35            5            7          756         NaN   \n",
       "4       350.0          84            5            8         1145         NaN   \n",
       "\n",
       "   YearBuilt  YearRemodAdd  SalePrice  \n",
       "0       2003          2003     208500  \n",
       "1       1976          1976     181500  \n",
       "2       2001          2002     223500  \n",
       "3       1915          1970     140000  \n",
       "4       2000          2000     250000  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = (pd.read_csv(\"outputs/datasets/collection/HousePricesRecords.csv\"))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested to get more familiar with the dataset, check variable type and distribution, missing levels and what these variables mean in a business context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "PydanticImportError",
     "evalue": "`BaseSettings` has been moved to the `pydantic-settings` package. See https://docs.pydantic.dev/2.0.2/migration/#basesettings-has-moved-to-pydantic-settings for more details.\n\nFor further information visit https://errors.pydantic.dev/2.0.2/u/import-error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPydanticImportError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m \u001b[39mimport\u001b[39;00m ProfileReport\n\u001b[1;32m      2\u001b[0m pandas_report \u001b[39m=\u001b[39m ProfileReport(df\u001b[39m=\u001b[39mdf, minimal\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m pandas_report\u001b[39m.\u001b[39mto_notebook_iframe()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/pandas_profiling/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"Main module of pandas-profiling.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39m.. include:: ../../README.md\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcontroller\u001b[39;00m \u001b[39mimport\u001b[39;00m pandas_decorator\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprofile_report\u001b[39;00m \u001b[39mimport\u001b[39;00m ProfileReport\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/pandas_profiling/controller/pandas_decorator.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"This file add the decorator on the DataFrame object.\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mimport\u001b[39;00m DataFrame\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprofile_report\u001b[39;00m \u001b[39mimport\u001b[39;00m ProfileReport\n\u001b[1;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprofile_report\u001b[39m(df: DataFrame, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ProfileReport:\n\u001b[1;32m      8\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Profile a DataFrame.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m        A ProfileReport of the DataFrame.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/pandas_profiling/profile_report.py:13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mvisions\u001b[39;00m \u001b[39mimport\u001b[39;00m VisionsTypeset\n\u001b[0;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m Config, Settings\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexpectations_report\u001b[39;00m \u001b[39mimport\u001b[39;00m ExpectationsReport\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malerts\u001b[39;00m \u001b[39mimport\u001b[39;00m AlertType\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/pandas_profiling/config.py:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39menum\u001b[39;00m \u001b[39mimport\u001b[39;00m Enum\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, Dict, List, Optional\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseModel, BaseSettings, Field\n\u001b[1;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_merge_dictionaries\u001b[39m(dict1: \u001b[39mdict\u001b[39m, dict2: \u001b[39mdict\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[1;32m      9\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m    Recursive merge dictionaries.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39m    :return: Merged dictionary\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/pydantic/__init__.py:206\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr_name)\u001b[0m\n\u001b[1;32m    204\u001b[0m dynamic_attr \u001b[39m=\u001b[39m _dynamic_imports\u001b[39m.\u001b[39mget(attr_name)\n\u001b[1;32m    205\u001b[0m \u001b[39mif\u001b[39;00m dynamic_attr \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m     \u001b[39mreturn\u001b[39;00m _getattr_migration(attr_name)\n\u001b[1;32m    208\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimportlib\u001b[39;00m \u001b[39mimport\u001b[39;00m import_module\n\u001b[1;32m    210\u001b[0m module \u001b[39m=\u001b[39m import_module(_dynamic_imports[attr_name], package\u001b[39m=\u001b[39m__package__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/pydantic/_migration.py:279\u001b[0m, in \u001b[0;36mgetattr_migration.<locals>.wrapper\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[39mreturn\u001b[39;00m import_string(DEPRECATED_MOVED_IN_V2[import_path])\n\u001b[1;32m    278\u001b[0m \u001b[39mif\u001b[39;00m import_path \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpydantic:BaseSettings\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[39mraise\u001b[39;00m PydanticImportError(\n\u001b[1;32m    280\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m`BaseSettings` has been moved to the `pydantic-settings` package. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSee https://docs.pydantic.dev/\u001b[39m\u001b[39m{\u001b[39;00mVERSION\u001b[39m}\u001b[39;00m\u001b[39m/migration/#basesettings-has-moved-to-pydantic-settings \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mfor more details.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    283\u001b[0m     )\n\u001b[1;32m    284\u001b[0m \u001b[39mif\u001b[39;00m import_path \u001b[39min\u001b[39;00m REMOVED_IN_V2:\n\u001b[1;32m    285\u001b[0m     \u001b[39mraise\u001b[39;00m PydanticImportError(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m`\u001b[39m\u001b[39m{\u001b[39;00mimport_path\u001b[39m}\u001b[39;00m\u001b[39m` has been removed in V2.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mPydanticImportError\u001b[0m: `BaseSettings` has been moved to the `pydantic-settings` package. See https://docs.pydantic.dev/2.0.2/migration/#basesettings-has-moved-to-pydantic-settings for more details.\n\nFor further information visit https://errors.pydantic.dev/2.0.2/u/import-error"
     ]
    }
   ],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "pandas_report = ProfileReport(df=df, minimal=True)\n",
    "pandas_report.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Study\n",
    "We use .corr() for spearman method, and sort the correlations in descending order. We start with numeric variables such as '1stFlrSF' (First Floor square feet). For each variable we remove missing data and zeros and calculate the correlation coefficient between the variable and the sale price. We store it in a list and convert the list to a Pandas Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Some of the variables in the dataset contain NaN. Check and remove those before using this transformer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfeature_engine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mencoding\u001b[39;00m \u001b[39mimport\u001b[39;00m OneHotEncoder\n\u001b[1;32m      2\u001b[0m encoder \u001b[39m=\u001b[39m OneHotEncoder(variables\u001b[39m=\u001b[39mdf\u001b[39m.\u001b[39mcolumns[df\u001b[39m.\u001b[39mdtypes\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto_list(), drop_last\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m df_ohe \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39;49mfit_transform(df)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(df_ohe\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      5\u001b[0m df_ohe\u001b[39m.\u001b[39mhead(\u001b[39m3\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/sklearn/base.py:915\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 915\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    916\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    918\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/feature_engine/encoding/one_hot.py:213\u001b[0m, in \u001b[0;36mOneHotEncoder.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    211\u001b[0m X \u001b[39m=\u001b[39m check_X(X)\n\u001b[1;32m    212\u001b[0m variables_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_or_select_variables(X)\n\u001b[0;32m--> 213\u001b[0m _check_contains_na(X, variables_)\n\u001b[1;32m    215\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder_dict_ \u001b[39m=\u001b[39m {}\n\u001b[1;32m    217\u001b[0m \u001b[39mfor\u001b[39;00m var \u001b[39min\u001b[39;00m variables_:\n\u001b[1;32m    218\u001b[0m \n\u001b[1;32m    219\u001b[0m     \u001b[39m# make dummies only for the most popular categories\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/feature_engine/dataframe_checks.py:266\u001b[0m, in \u001b[0;36m_check_contains_na\u001b[0;34m(X, variables)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39mChecks if DataFrame contains null values in the selected columns.\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39m    If the variable(s) contain null values.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39mif\u001b[39;00m X[variables]\u001b[39m.\u001b[39misnull()\u001b[39m.\u001b[39many()\u001b[39m.\u001b[39many():\n\u001b[0;32m--> 266\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    267\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSome of the variables in the dataset contain NaN. Check and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mremove those before using this transformer.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    269\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Some of the variables in the dataset contain NaN. Check and remove those before using this transformer."
     ]
    }
   ],
   "source": [
    "lst = []\n",
    "# Remove first zeros and missing values\n",
    "for col in df.columns[df.dtypes!='object'].to_list():\n",
    "    if col != 'SalePrice':\n",
    "        df1 = df[df[col]!=0]\n",
    "        df2 = df1[df1[col].notnull()]\n",
    "        df3 = df2.filter(['SalePrice', col])\n",
    "        corr_spearman = df3.corr(method='spearman')['SalePrice'][1:].round(2)\n",
    "        lst.append(corr_spearman[col])\n",
    "corr_num = pd.Series(index=df.columns[df.dtypes!='object'].drop(['SalePrice']).to_list(), data=lst).sort_values(key=abs, ascending=False)\n",
    "print(corr_num)"
   ]
  },
  {
   "source": [
    "* To calculate the correlation coefficients of the four object variables, we first encode them to numeric variables manually.\n",
    "\n",
    "**BsmtExposure:** Refers to walkout or garden level walls Gd: Good Exposure; Av: Average Exposure; Mn: Mimimum Exposure; No: No Exposure; None: No Basement\n",
    "\n",
    "**BsmtFinType1:** Rating of basement finished area GLQ: Good Living Quarters; ALQ: Average Living Quarters; BLQ: Below Average Living Quarters; Rec: Average Rec Room; LwQ: Low Quality; Unf: Unfinshed; None: No Basement\n",
    "\n",
    "**GarageFinish:** Interior finish of the garage Fin: Finished; RFn: Rough Finished; Unf: Unfinished; None: No Garage\n",
    "\n",
    "**KitchenQual:** Kitchen quality Ex: Excellent; Gd: Good; TA: Typical/Average; Fa: Fair; Po: Poor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dictionary dic maps the ordinal categorical values to integers for the four object variables.\n",
    "dic = {'BsmtExposure': {'Gd': 3, 'Av': 2, 'Mn': 1, 'No': 0}, 'BsmtFinType1': {'GLQ': 5, 'ALQ': 4, 'BLQ': 3, 'Rec': 2, 'LwQ': 1, 'Unf': 0}, 'GarageFinish': {'Fin': 2, 'RFn': 1, 'Unf': 0}, 'KitchenQual': {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'Po': 0}}\n",
    "lst = []\n",
    "# Remove first None and missing values\n",
    "for col in df.columns[df.dtypes=='object'].to_list():\n",
    "    df1 = df[df[col]!='None']\n",
    "    df2 = df1[df1[col].notnull()]\n",
    "    df3[col] = df2[col].replace(dic[col])\n",
    "    df4 = df3.filter(['SalePrice', col])\n",
    "    corr_spearman = df4.corr(method='spearman')['SalePrice'][1:].round(2)\n",
    "    lst.append(corr_spearman[col])\n",
    "corr_object = pd.Series(index=df.columns[df.dtypes=='object'].to_list(), data=lst).sort_values(key=abs, ascending=False)\n",
    "print(corr_object)"
   ]
  },
  {
   "source": [
    "* **Combine both series of correlation coefficients and sort in ascending order for the heatnap:**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = corr_num.append(corr_object).sort_values(key=abs, ascending=False).round(2)\n",
    "corr_df = pd.DataFrame(index=['SalePrice'], columns=corr.index, data=corr.values.reshape(1,-1).tolist())\n",
    "corr_df_rev = corr_df[corr_df.columns[::-1]]\n",
    "corr"
   ]
  },
  {
   "source": [
    "## Heatmap for correlation coefficients\n",
    "* Heatmap for correlation coefficients between house attributes and sale price"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig, axes = plt.subplots(figsize=(15,6))\n",
    "annot_size = 8\n",
    "\n",
    "# Retain only correlation values above 0.4\n",
    "mask = np.zeros_like(corr_df_rev, dtype=np.bool)\n",
    "mask[corr_df_rev.abs() < 0.4] = True\n",
    "\n",
    "sns.heatmap(data=corr_df_rev, annot=True, xticklabels=True, yticklabels=True,\n",
    "            mask=mask, cmap='viridis', annot_kws={\"size\": annot_size}, ax=axes,\n",
    "            linewidth=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "The moderately strong correlation coefficients have values between 0.4 and 0.6. The strong correlation coefficients have values above 0.6. The house attribute most strongly correlated to the house price (with correlation coefficient 0.81) is the overall quality ('OverallQual') variable which is an ordinal variable."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype_dic is a dictionary used to choose between a scatterplot and a strip plot\n",
    "strongly_correlated = ['OverallQual', 'GrLivArea', '2ndFlrSF', 'KitchenQual', 'YearBuilt', 'GarageArea', 'GarageFinish']\n",
    "moderately_correlated = ['GarageYrBlt', '1stFlrSF', 'TotalBsmtSF', 'YearRemodAdd', 'LotArea', 'LotFrontage', 'BsmtFinSF1']\n",
    "dtype_dict = {'OverallQual': 'object', 'GrLivArea': 'numeric', '2ndFlrSF': 'numeric', 'KitchenQual': 'object', 'YearBuilt': 'numeric', 'GarageArea': 'numeric', 'GarageFinish': 'object', 'GarageYrBlt': 'numeric', '1stFlrSF': 'numeric', 'TotalBsmtSF': 'numeric', 'YearRemodAdd': 'numeric', 'LotArea': 'numeric', 'LotFrontage': 'numeric', 'BsmtFinSF1': 'numeric'}"
   ]
  },
  {
   "source": [
    "## Scatterplots between house attributes and sale price"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove first zeros/None values and missing values\n",
    "for col in strongly_correlated:\n",
    "    if df[col].dtype == 'object':\n",
    "        df1 = df[df[col]!='None']\n",
    "        df2 = df1[df1[col].notnull()]\n",
    "        df3[col] = df2[col].replace(dic[col])\n",
    "    else:\n",
    "        df1 = df[df[col]!=0]\n",
    "        df3 = df1[df1[col].notnull()]\n",
    "    if dtype_dict[col] == 'object':\n",
    "        fig, axes = plt.subplots(figsize=(12,6))\n",
    "        sns.stripplot(data=df3, x=col, y='SalePrice')\n",
    "        plt.show()\n",
    "    elif dtype_dict[col] == 'numeric':\n",
    "        fig, axes = plt.subplots(figsize=(12,6))\n",
    "        sns.scatterplot(data=df3, x=col, y='SalePrice', alpha=0.5)\n",
    "        plt.show()\n",
    "\n",
    "for col in moderately_correlated:\n",
    "    if df[col].dtype == 'object':\n",
    "        df1 = df[df[col]!='None']\n",
    "        df2 = df1[df1[col].notnull()]\n",
    "        df3[col] = df2[col].replace(dic[col])\n",
    "    else:\n",
    "        df1 = df[df[col]!=0]\n",
    "        df3 = df1[df1[col].notnull()]\n",
    "    if dtype_dict[col] == 'object':\n",
    "        fig, axes = plt.subplots(figsize=(12,6))\n",
    "        sns.stripplot(data=df, x=col, y='SalePrice')\n",
    "        plt.show()\n",
    "    elif dtype_dict[col] == 'numeric':\n",
    "        fig, axes = plt.subplots(figsize=(12,6))\n",
    "        sns.scatterplot(data=df, x=col, y='SalePrice', alpha=0.5)\n",
    "        plt.show()"
   ]
  },
  {
   "source": [
    "We see that the stronger the correlation the clearer the trend"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Explore sale price distribution"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from Code Institute Scikit lesson\n",
    "sns.set_style(\"whitegrid\")\n",
    "def plot_histogram_and_boxplot(df):\n",
    "  for col in df.columns:\n",
    "    fig, axes = plt.subplots(nrows=2 ,ncols=1 ,figsize=(7,7), gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    "    sns.boxplot(data=df, x=col, ax=axes[0], whis=3)\n",
    "    sns.histplot(data=df, x=col, kde=True, ax=axes[1])\n",
    "    fig.suptitle(f\"{col} Distribution - Boxplot and Histogram\")\n",
    "    plt.show()\n",
    "\n",
    "    # An outlier is defined to be outside the box in the boxplot by three times the\n",
    "    # interquantile distance\n",
    "    IQR = df[col].quantile(q=0.75) - df[col].quantile(q=0.25)\n",
    "    print(\n",
    "        f\"This is the range where a datapoint is not an outlier: from \"\n",
    "        f\"{(df[col].quantile(q=0.25) - 3*IQR).round(2)} to \"\n",
    "        f\"{(df[col].quantile(q=0.75) + 3*IQR).round(2)}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.filter(['SalePrice'])\n",
    "plot_histogram_and_boxplot(df2)"
   ]
  },
  {
   "source": [
    "* We see that the distribution has a long right tail or in other words it is skewed to the right."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Store correlation coefficients dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "version = 'v1'\n",
    "file_path = f'outputs/house_prices_study/{version}'\n",
    "\n",
    "try:\n",
    "  os.makedirs(name=file_path)\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df_rev.to_csv(f\"{file_path}/corr_df_rev.csv\", index=False)"
   ]
  },
  {
   "source": [
    "## Store dictionary used for encoding object variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=dic, filename=f\"{file_path}/dic.pkl\")"
   ]
  },
  {
   "source": [
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}