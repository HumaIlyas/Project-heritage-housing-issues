{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "*   Encode categorical variables and handle missing data\n",
    "*   Clean data\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* outputs/datasets/collection/HeritageHousing.csv\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Generate a pipeline that performs the data cleaning\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "  * Data Cleaning Pipeline\n",
    "  * Two variables have more than 90% missing values and can be dropped, seven more variables have missing values and those values can be replaced with the variable's median\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chdir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Collected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = (pd.read_csv(\"outputs/datasets/collection/HousePricesRecords.csv\"))\n",
    "df.head(3)"
   ]
  },
  {
   "source": [
    "## Encode object variables:\n",
    "\n",
    "#### There is four object variables:\n",
    "\n",
    "**BsmtExposure:** Refers to walkout or garden level walls Gd: Good Exposure; Av: Average Exposure; Mn: Mimimum Exposure; No: No Exposure; None: No Basement\n",
    "\n",
    "**BsmtFinType1:** Rating of basement finished area GLQ: Good Living Quarters; ALQ: Average Living Quarters; BLQ: Below Average Living Quarters; Rec: Average Rec Room; LwQ: Low Quality; Unf: Unfinshed; None: No Basement\n",
    "\n",
    "**GarageFinish:** Interior finish of the garage Fin: Finished; RFn: Rough Finished; Unf: Unfinished; None: No Garage\n",
    "\n",
    "**KitchenQual:** Kitchen quality Ex: Excellent; Gd: Good; TA: Typical/Average; Fa: Fair; Po: Poor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to map the categories of the four object variables to numbers.\n",
    "# It maps None to zero in contrast to the dictionary used in the HouseSalePrices\n",
    "# notebook where we discarded None values.\n",
    "dic = {'BsmtExposure': {'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, 'None': 0}, 'BsmtFinType1': {'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, 'None': 0}, 'GarageFinish': {'Fin': 3, 'RFn': 2, 'Unf': 1, 'None': 0}, 'KitchenQual': {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'Po': 0}}\n",
    "df2=df.copy()\n",
    "for col in df.columns[df.dtypes=='object'].to_list():\n",
    "    df2[col] = df2[col].replace(dic[col])\n",
    "df2.head()"
   ]
  },
  {
   "source": [
    "### Perform the same encoding as above but with a custom transformer that can be used in a pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# create a Class variable with a fit and transform method\n",
    "class MyCustomEncoder(BaseEstimator, TransformerMixin):\n",
    "\n",
    "  def __init__(self, variables, dic):\n",
    "    if not isinstance(variables, list): \n",
    "      self.variables = [variables]\n",
    "    else: self.variables = variables\n",
    "    self.dic = dic\n",
    "\n",
    "  def fit(self, X, y=None):    \n",
    "    return self\n",
    "\n",
    "  def transform(self, X):\n",
    "    for col in self.variables:\n",
    "      if X[col].dtype == 'object':\n",
    "        X[col] = X[col].replace(dic[col])\n",
    "      else:\n",
    "        print(f\"Warning: {col} data type should be object to use MyCustomEncoder()\")\n",
    "      \n",
    "    return X\n",
    "\n",
    "# use the custom encoder in a pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([('custom_encoder', MyCustomEncoder(variables=['BsmtExposure', 'BsmtFinType1', 'GarageFinish', 'KitchenQual'], dic=dic))])\n",
    "\n",
    "df2 = df.copy()\n",
    "df2 = pipeline.fit_transform(df2)\n",
    "df2.head(3)"
   ]
  },
  {
   "source": [
    "## Missing data\n",
    "\n",
    "* Find out which variables have missing data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_with_missing_data = df.columns[df.isna().sum() > 0].to_list()\n",
    "vars_with_missing_data"
   ]
  },
  {
   "source": [
    "#### Explore the variables with missing data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "profile = ProfileReport(df=df[vars_with_missing_data], minimal=True)\n",
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "source": [
    "### Drop variables\n",
    "\n",
    "* The variables 'EnclosedPorch' and 'WoodDeckSF' have about 90% missing data and can be dropped."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.selection import DropFeatures\n",
    "drop_features = DropFeatures(features_to_drop = ['EnclosedPorch', 'WoodDeckSF'])\n",
    "\n",
    "df_transformed = drop_features.fit_transform(df)\n",
    "df_transformed.info()"
   ]
  },
  {
   "source": [
    "### Replace missing data with median"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_with_missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'EnclosedPorch' and 'WoodDeckSF' from vars_with_missing_dat since we drop them\n",
    "vars_with_missing_data = ['2ndFlrSF', 'BedroomAbvGr', 'BsmtFinType1', 'GarageFinish', 'GarageYrBlt', 'LotFrontage', 'MasVnrArea']\n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "\n",
    "pipeline = Pipeline([\n",
    "      ('drop_features', DropFeatures(features_to_drop = ['EnclosedPorch', 'WoodDeckSF'])),\n",
    "      ('custom_encoder', MyCustomEncoder(variables=['BsmtExposure', 'BsmtFinType1', 'GarageFinish', 'KitchenQual'], dic=dic)),\n",
    "      ('median_imputer',  MeanMedianImputer(imputation_method='median', variables=vars_with_missing_data))\n",
    "])\n",
    "\n",
    "df2 = df.copy()\n",
    "df_transformed = pipeline.fit_transform(df2) \n",
    "df_transformed.head(5)   "
   ]
  },
  {
   "source": [
    "* Check that there is no missing data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_with_missing_data = df_transformed.columns[df_transformed.isna().sum() > 0].to_list()\n",
    "vars_with_missing_data"
   ]
  },
  {
   "source": [
    "* Print the computed median for each feature"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline['median_imputer'].imputer_dict_"
   ]
  },
  {
   "source": [
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}